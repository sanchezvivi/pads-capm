---
title: "Modelos Dinâmicos em Soft Commodities"
subtitle: "Financial Analytics"
institute: "Programa Avançado em Data Science - Insper"
author: "Luis Fechio, Viviane Sanchez"
date: "11/28/2020"
output: #ioslides_presentation
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
#runtime: shiny
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
  fig.showtext = TRUE,
  fig.width = 16, 
  fig.height = 8, 
  dpi = 300
)

library(RcppRoll)
library(bizdays)
library(derivmkts)

library(ggrepel)
library(highcharter)
library(shiny)
library(flexdashboard)
library(knitr)
library(skimr)

library(timetk)

library(tidyquant)
library(tidymodels)
library(tidyverse)

library(dlm)
library(rugarch)

load_rmetrics_calendars(2000:year(Sys.Date())+1)
#calendars()
bizdays.options$set(default.calendar='Rmetrics/NYSE')

theme_set(theme_minimal())
theme_update(text = element_text(family = "Open Sans"),
             plot.title = element_text(face = "bold", size = 23,
                                       color = "#1d3752"),
             legend.position = "bottom")

hc_cols <- c("#7cb5ec", "#434348", "#90ed7d", "#f7a35c", 
             "#8085e9", "#f15c80", "#e4d354", "#2b908f", 
             "#f45b5b", "#91e8e1")

options(digits=6)

quandl_api_key(Sys.getenv("QUANDL_TOKEN"))

#- como colocar o token no ambiente:
#
#abra o ambiente com o comando
#`usethis::edit_r_environ()`
#
# copie a linha abaixo com seu token
#
#QUANDL_TOKEN=(token)


#upgrade xaringan

#remotes::install_github('yihui/xaringan', upgrade = TRUE)

#xaringan::inf_mr()

```

# Introdução

Modelagem dinâmica dos preços das commodities softs listadas na [Intercontinental Exchange (ICE)](https://www.theice.com/products/Futures-Options/Agriculture)

- Açúcar VHP - `sugar`
- Cacau - `cocoa`
- Algodão - `cotton`
- Café - `coffee`
- Suco de laranja congelado - `orange_juice`

Como benchmark, será utilizado ..... (BRL? DXY? BCOM?)

[BCOM](https://www.bloomberg.com/company/press/bloomberg-commodity-index-2020-target-weights-announced/)

---

# Objetivo

comparar cada método, explicitando os prós e contras de cada alternativa e fazer uma conclusão de qual deles considera mais apropriado para cada ativo. A avaliação do método mais adequado deverá ser tanto em termos do que faz sentido teórico (interpretação dos coeficientes ao longo do tempo) quanto em termos quantitativos ao realizar um backtest e comparar as métricas para diferentes abordagens.


---

## Preços

```{r Read Prices, echo=FALSE}

cmdty_name <- c("sugar","cocoa","cotton","coffee", "orange_juice", "xbcom")

tickers <-  c("CHRIS/ICE_SB1", "CHRIS/ICE_CC1", 
              "CHRIS/ICE_CT1","CHRIS/ICE_KC1", 
              "CHRIS/ICE_OJ1", "CHRIS/CME_AW1")

cmdty_raw <- tq_get(tickers, get = "quandl", from = "2018-01-01", to  = Sys.Date()) %>% 
              #na.omit() %>% 
  left_join(tibble(cmdty = cmdty_name,
                   symbol = tickers), by = "symbol") %>% 
            group_by(symbol) %>% 
                   tq_mutate(select = settle,
                            mutate_fun = periodReturn,
                            period = "daily",
                            method = "log",
                            col_rename = "daily_return") %>% 
                  tq_mutate(select = settle,
                            mutate_fun = volatility,
                            col_rename = "hist_vol") %>%
            mutate(acc_return = exp(cumsum(daily_return))-1,
                    sq_return = daily_return^2) %>% 
            ungroup()
  

#cmdty_raw %>% 
 # glimpse

#conv_tb <- tibble(cmdty =  c("sugar","cocoa","cotton","coffee", "orange_juice"),
#                  contract_size = c(112000, 10, 50000, 37500, 15000),
#                  unit = c("lb", "lb", "lb","t","lb"),
#                  tick_size = c(0.01, 1, 0.01, 0.05, 0.05))
#
```

## Série de preços

```{r Grafico1 - Prices}

cmdty_raw %>% 
    #mutate(daily_return = daily_return*100) %>% 
      hchart(., "line", 
             hcaes(x = date, y = settle, group = cmdty)) %>% 
      #hc_colors(cols) %>%
      hc_tooltip(valueDecimals = 2) %>% 
      hc_xAxis(title = list(text = "Data")) %>% 
      hc_yAxis(title = list(text = "Settle"))

```

---
## Série de Retornos

```{r Grafico2 - Retornos}

cmdty_raw %>% 
      mutate(daily_return = daily_return*100) %>% 
      hchart(., "line", 
             hcaes(x = date, y = daily_return, group = cmdty)) %>% 
      #hc_colors(cols) %>%
      hc_tooltip(valueDecimals = 2) %>% 
      hc_xAxis(title = list(text = "Data")) %>% 
      hc_yAxis(title = list(text = "Retorno Diário"),
               labels = list(format = "{value}%"))

```


## Retorno Acumulado

```{r Grafico3 - Retornos}

cmdty_raw %>% 
      mutate(daily_return = daily_return*100) %>% 
      hchart(., "line", 
             hcaes(x = date, y = acc_return, group = cmdty)) %>% 
      #hc_colors(cols) %>%
      hc_tooltip(valueDecimals = 2) %>% 
      hc_xAxis(title = list(text = "Data")) %>% 
      hc_yAxis(title = list(text = "Retorno Acumulado"),
               labels = list(format = "{value}%"))

```

---
## Volatilidade

```{r}

cmdty_raw %>% #group_by(cmdty) %>% summarise(mean(hist_vol, na.rm = T))
      mutate(sq_return = sq_return *100) %>% 
      mutate(hist_vol = hist_vol*100) %>% 
      hchart(., "line", 
             hcaes(x = date, y = hist_vol, group = cmdty)) %>% 
      #hc_colors(cols) %>%
      hc_tooltip(valueDecimals = 2) %>% 
      hc_xAxis(title = list(text = "Data")) %>% 
      hc_yAxis(title = list(text = "Proxy da Volatilidade"),
               labels = list(format = "{value}%"))

```

# CAPM 

## CAPM Estático

```{r echo = FALSE}

# preparação da base
returns_tb <- cmdty_raw %>% 
  filter(cmdty != "xbcom") %>%  
  select(cmdty, date, daily_return) %>% 
  left_join(cmdty_raw %>%  
              select(cmdty, date, daily_return) %>% 
              filter(cmdty == "xbcom") %>% 
              rename(benchmark = cmdty, 
                     bmk_return = daily_return), by = "date") %>% 
  na.omit() %>% 
  select(-date) %>% 
  group_by(cmdty) %>% 
  nest(returns = c(daily_return, bmk_return))

# ajuste dos modelos
tidy_capm <- returns_tb %>% 
  mutate(model = map(returns, ~lm(daily_return ~ bmk_return, data = .x)))
  
# resuttado dos modelos
tidy_lm <- tidy_capm %>%
  mutate(coefs = map(model, tidy)) %>%
  unnest(coefs) %>%
  #filter(term == "bmk_return") %>%
  mutate(p.value = p.adjust(p.value))

```

## Resultados

```{r echo = FALSE}

tidier_lm <- tidy_lm %>% 
  pivot_wider(names_from = term, values_from = estimate) %>% 
  janitor::clean_names() %>% 
  fill(intercept) %>% na.omit() %>% 
  rename(alpha = intercept,
        beta = bmk_return)

tidier_lm %>% 
  unnest(returns) %>% 
  ggplot(aes(x = bmk_return, y = daily_return, color = cmdty)) +
  geom_point(alpha  = 0.3) +
  geom_abline(aes(intercept = alpha, slope = beta))+ 
  geom_smooth(method = "lm", linetype = 2, size = 0.5, show.legend = F)+
  facet_wrap(~cmdty)+
  scale_color_manual(values = hc_cols) +
  labs(x = "Benchmark Returns", y = "Commodity Returns")

```

```{r}

tidy_lm %>%
  mutate(term = if_else(term == "bmk_return", "beta", "alpha")) %>% 
  #filter(term == "bmk_return") %>%
  ggplot(aes(estimate, p.value, label = cmdty)) +
  geom_vline(xintercept = 0, lty = 2,
    size = 1.5, alpha = 0.7, color = "gray50") +
  geom_point(aes(color = cmdty), alpha = 0.8, size = 2.5, show.legend = FALSE) +
  scale_y_log10() +
  facet_wrap(~term) +
  geom_text_repel(size = 3) +
  scale_color_manual(values = hc_cols)

```

## CAPM Rolling Window

```{r echo = FALSE}

sugarRets <- returns_tb %>% unnest(col = 'returns') %>% filter(cmdty == 'sugar')
cocoaRets <- returns_tb %>% unnest(col = 'returns') %>% filter(cmdty == 'cocoa')
cottonRets <- returns_tb %>% unnest(col = 'returns') %>% filter(cmdty == 'cotton')
coffeeRets <- returns_tb %>% unnest(col = 'returns') %>% filter(cmdty == 'coffee')
orangeRets <- returns_tb %>% unnest(col = 'returns') %>% filter(cmdty == 'orange_juice')

nPer <- nrow(sugarRets)
nDiv <- 2
w0 <- round(nPer/nDiv, 0)
wf <- (nPer - w0)

rBetas <- matrix(NA, wf, 5)
for (t in 1:wf){
  sugar_fit = lm(sugarRets$daily_return[t:(w0+t)] ~ sugarRets$bmk_return[t:(w0+t)])
  cocoa_fit = lm(cocoaRets$daily_return[t:(w0+t)] ~ cocoaRets$bmk_return[t:(w0+t)])
  cotton_fit = lm(cottonRets$daily_return[t:(w0+t)] ~ cottonRets$bmk_return[t:(w0+t)])
  coffee_fit = lm(coffeeRets$daily_return[t:(w0+t)] ~ coffeeRets$bmk_return[t:(w0+t)])
  orange_fit = lm(orangeRets$daily_return[t:(w0+t)] ~ orangeRets$bmk_return[t:(w0+t)])

  rBetas[t,]= c(sugar_fit$coefficients[2],
               cocoa_fit$coefficients[2],
               cotton_fit$coefficients[2],
               coffee_fit$coefficients[2],
               orange_fit$coefficients[2])
}

sBetas <- tidy_lm %>% filter(term == 'bmk_return') %>% select(cmdty, estimate)
ts.plot(rBetas, col=hc_cols[1:5], lwd=2, ylim=c(0.00,1), main='Rolling Betas')
abline(h=filter(sBetas, cmdty == 'sugar')[2], col=hc_cols[1], lty=2)
abline(h=filter(sBetas, cmdty == 'cocoa')[2], col=hc_cols[2], lty=2)
abline(h=filter(sBetas, cmdty == 'cotton')[2], col=hc_cols[3], lty=2)
abline(h=filter(sBetas, cmdty == 'coffee')[2], col=hc_cols[4], lty=2)
abline(h=filter(sBetas, cmdty == 'orange_juice')[2], col=hc_cols[5], lty=2)
abline(h=1, col=hc_cols[6], lty=1)
legend("bottom", col=hc_cols[1:5], lty=1,
       legend=cmdty_name[1:5],
       lwd = 2, cex=0.6, box.lty=2)




```

## CAPM Dinâmico

```{r}

# set up DLM
dlm_spec <-  function(parm, x.mat){
  parm <- exp(parm)
  return(dlmModReg(X=x.mat, dV=parm[1], dW=c(parm[2], parm[3])))
}

se_fun <- function(parameter){
  
  se <- sqrt(exp(parameter))
  
return(se)
    
}

# estimate parameters
tidy_dlm <- returns_tb %>% 
  unnest(returns) %>% 
  chop(c(bmk_return, daily_return)) %>% 
  mutate(model = map2(bmk_return, daily_return, ~dlmMLE(y = .y,
                                                        parm = c(1,1,1),
                                                        x.mat = .x,
                                                        build = dlm_spec,
                                                        hessian=T)))
# get estimates - verificar aplicação com map
tidy_estimates <- tidy_dlm %>% 
  unnest_wider(model) %>% #pull(par)
  mutate(se = map(par, se_fun))

tidy_estimates %>% 
  select(cmdty, se) %>% 
  unnest_wider(se) %>% 
  kable()

# get parameter estimates over time
# these are the smoothed state values
  
```

### Filtered and Smoothed States

```{r}

dates <- cmdty_raw %>% 
  filter(cmdty != "xbcom") %>%  
  select(cmdty, date, daily_return) %>% 
  left_join(cmdty_raw %>%  
              select(cmdty, date, daily_return) %>% 
              filter(cmdty == "xbcom") %>% 
              rename(benchmark = cmdty, 
                     bmk_return = daily_return), by = "date") %>% 
  na.omit() %>% 
  select(cmdty,date) %>% 
  group_by(cmdty) %>% 
  chop(date)

tidy_filter <- tidy_estimates %>% 
  select(cmdty, bmk_return, daily_return, par) %>% 
  mutate(adj_spec = map2(par, bmk_return, ~dlm_spec(.x, .y))) %>% 
  mutate(dlm_filter = map2(daily_return, adj_spec, ~dlmFilter(.x,.y))) %>% 
  mutate(dlm_smooth = map(dlm_filter, dlmSmooth)) %>% 
  left_join(dates, by = "cmdty") %>% 
  ungroup()
  

tidy_smooth <- tidy_filter %>% 
  unnest_wider(dlm_smooth)


  # plot filtered and smoothed states
date <-  df.tickers$ref.date[df.tickers$ticker == 'AMZN'][-1]
plot(date,mod2f$m[,1][-1],xlab="day",ylab= expression(alpha[t]),type="l",main="")
lines(date,mod2s$s[,1][-1],col=2)
abline(h=capm_amazon$coef[1],col=3)
abline(h=1,lty=2)

date <-  df.tickers$ref.date[df.tickers$ticker == 'AMZN'][-1]
plot(date,mod2f$m[,2][-1],xlab="day",ylab=expression(beta[t]),type="l",main="")
lines(date,mod2s$s[,2][-1],col=2)
abline(h=capm_amazon$coef[2],col=3)
abline(h=1,lty=2)
  

```


## CAPM com modelo de Volatilidade

### GARCH Fit

```{r}

garch_var <- function(garch_fit){
  
  var <- garch_fit@fit$sigma^2
  
  return(var)
  
}

garch_spec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),
                    variance.model = list(model="sGARCH", garchOrder=c(1,1)),
                    distribution.model = "norm")

tidy_garch <- returns_tb %>% 
  unnest(returns) %>% 
  mutate(plus_mkt = daily_return + bmk_return,
         minus_mkt = daily_return - bmk_return) %>% 
  select(cmdty, plus_mkt, minus_mkt, bmk_return) %>% 
  group_by(cmdty) %>% 
  chop(c(plus_mkt, minus_mkt, bmk_return)) %>% 
  mutate(garch_plus = map(plus_mkt, ~ugarchfit(garch_spec, .x)),
         garch_minus = map(minus_mkt, ~ugarchfit(garch_spec, .x)),
         garch_bmk = map(bmk_return, ~ugarchfit(garch_spec, .x))) %>% 
  mutate(var_plus = map(garch_plus, garch_var),
         var_minus = map(garch_minus, garch_var),
         var_bmk = map(garch_bmk, garch_var)) %>% 
  left_join(dates, by = "cmdty")

tidy_betas <- tidy_garch %>% 
  select(cmdty, date, starts_with("var")) %>% 
  unchop(everything()) %>% 
  mutate(beta = (var_plus - var_minus)/(4*var_bmk))

```


### Time Varyig Betas

```{r}

tidy_betas %>% 
  ggplot(aes(date, beta, color = cmdty)) +
  geom_line() +
  facet_wrap(~cmdty, scales = "free") +
  scale_color_manual(values = hc_cols) +
  labs(x = "", y = "Beta")



```


### LAB

```{r}
spec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),
                    variance.model = list(model="sGARCH", garchOrder=c(1,1)),
                    distribution.model = "norm")

garch_mercado = ugarchfit(spec, data = mercado)

temp1 = itau + mercado
temp2 = itau - mercado

garch_mais = ugarchfit(spec, data = temp1)
garch_menos = ugarchfit(spec, data = temp2)

var_mercado = garch_mercado@fit$sigma^2
var_mais    = garch_mais@fit$sigma^2
var_menos   = garch_menos@fit$sigma^2

tvp_beta = (var_mais - var_menos)/(4*var_mercado)

ts.plot(tvp_beta, col=1, ylab='Ita?', main='Time-Varying Beta', lwd=1)
abline(h=itau_fit$coefficients[2], lty=2, lwd=2, col=2)



# Performance via Backtest

fitted = rep(NA, nrow(itau))
erro = rep(NA, nrow(itau))

for (t in 1:nrow(itau)){
  fitted[t] = tvp_beta[t]*mercado[t]
  erro[t]   = itau[t] - fitted[t] 
}

MSE_beta_garch = mean(erro^2)
MAE_beta_garch = mean(abs(erro))

MAE_beta_garch/MAE_itau_estatico

MSE_beta_garch/MSE_itau_estatico


# MOdelo com beta variando atrav?s do GARCH performa melhor que o beta est?tico!




```


# Referências

- [Train and analyze many models for #TidyTuesday crop yields](https://juliasilge.com/blog/crop-yields/)
